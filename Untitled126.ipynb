{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1767dd70-64a7-4fd3-baa0-3cc935d97aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in ./anaconda3/lib/python3.11/site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (from openai-whisper) (1.25.0)\n",
      "Requirement already satisfied: torch in ./anaconda3/lib/python3.11/site-packages (from openai-whisper) (2.6.0)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.11/site-packages (from openai-whisper) (4.66.4)\n",
      "Requirement already satisfied: more-itertools in ./anaconda3/lib/python3.11/site-packages (from openai-whisper) (10.1.0)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./anaconda3/lib/python3.11/site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./anaconda3/lib/python3.11/site-packages (from tiktoken->openai-whisper) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./anaconda3/lib/python3.11/site-packages (from tiktoken->openai-whisper) (2.32.2)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (4.11.0)\n",
      "Requirement already satisfied: networkx in ./anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (2024.3.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./anaconda3/lib/python3.11/site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803405 sha256=7f3e0ae7718917d8f83fdfcd8e64dc3337b5e19a351c027d239a0b41e7e76511\n",
      "  Stored in directory: /Users/anrisroquedacosta/Library/Caches/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: tiktoken, openai-whisper\n",
      "Successfully installed openai-whisper-20240930 tiktoken-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai-whisper\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8a3a88fe-4841-4ed3-95da-54e095629898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_001_mic1.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_001_mic1.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_001_mic2.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_001_mic2.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_002_mic1.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_002_mic1.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_002_mic2.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_002_mic2.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_003_mic1.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_003_mic1.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_003_mic2.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_003_mic2.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_004_mic1.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_004_mic1.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_004_mic2.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_004_mic2.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_005_mic1.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_005_mic1.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_005_mic2.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_005_mic2.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_006_mic1.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_006_mic1.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_006_mic2.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_006_mic2.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_007_mic1.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_007_mic1.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_007_mic2.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_007_mic2.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_008_mic1.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_008_mic1.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_008_mic2.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_008_mic2.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_009_mic1.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_009_mic1.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_009_mic2.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_009_mic2.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_010_mic1.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_010_mic1.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_010_mic2.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_010_mic2.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_011_mic1.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_011_mic1.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_011_mic2.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_011_mic2.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_012_mic1.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_012_mic1.flac\n",
      "File downloaded from the given data/wav48_silence_trimmed/p225/p225_012_mic2.flac to /Users/anrisroquedacosta/Downloads/data/wav48_silence_trimmed/p225/p225_012_mic2.flac\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Execute the download process\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 61\u001b[0m     download_all_audio_files()\n",
      "Cell \u001b[0;32mIn[109], line 57\u001b[0m, in \u001b[0;36mdownload_all_audio_files\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Download all files to the Downloads directory\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_key \u001b[38;5;129;01min\u001b[39;00m file_keys:\n\u001b[0;32m---> 57\u001b[0m     download_audio_from_s3_bucket_(file_key)\n",
      "Cell \u001b[0;32mIn[109], line 22\u001b[0m, in \u001b[0;36mdownload_audio_from_s3_bucket_\u001b[0;34m(file_key)\u001b[0m\n\u001b[1;32m     19\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(local_filename), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Download the file from the S3 bucket\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m s3_client\u001b[38;5;241m.\u001b[39mdownload_file(bucket_name, file_key, local_filename)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Print the downloaded file path for debugging\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile downloaded from the given \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/botocore/context.py:123\u001b[0m, in \u001b[0;36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[1;32m    122\u001b[0m     hook()\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/boto3/s3/inject.py:223\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Download an S3 object to a file.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mUsage::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    transfer.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transfer\u001b[38;5;241m.\u001b[39mdownload_file(\n\u001b[1;32m    224\u001b[0m         bucket\u001b[38;5;241m=\u001b[39mBucket,\n\u001b[1;32m    225\u001b[0m         key\u001b[38;5;241m=\u001b[39mKey,\n\u001b[1;32m    226\u001b[0m         filename\u001b[38;5;241m=\u001b[39mFilename,\n\u001b[1;32m    227\u001b[0m         extra_args\u001b[38;5;241m=\u001b[39mExtraArgs,\n\u001b[1;32m    228\u001b[0m         callback\u001b[38;5;241m=\u001b[39mCallback,\n\u001b[1;32m    229\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/boto3/s3/transfer.py:406\u001b[0m, in \u001b[0;36mS3Transfer.download_file\u001b[0;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[1;32m    402\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mdownload(\n\u001b[1;32m    403\u001b[0m     bucket, key, filename, extra_args, subscribers\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# their own retries.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3TransferRetriesExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/s3transfer/futures.py:114\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/s3transfer/futures.py:111\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/s3transfer/futures.py:267\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Waits until TransferFuture is done and returns the result\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03mIf the TransferFuture succeeded, it will return the result. If the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03mTransferFuture failed, it will raise the exception associated to the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mfailure.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Doing a wait() with no timeout cannot be interrupted in python2 but\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# can be interrupted in python3 so we just wait with the largest\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# possible value integer value, which is on the scale of billions of\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# years...\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done_event\u001b[38;5;241m.\u001b[39mwait(MAXINT)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "# Accessing the data\n",
    "s3_client = boto3.client('s3',\n",
    "    aws_access_key_id='cb5eb34e7737acb9296ff550121d1d6b',\n",
    "    aws_secret_access_key='2081f620ecea1cf0166389256f1ef2208865bb5349216faa2898b42fffe8a2d4',\n",
    "    endpoint_url='https://bdadc4417ecd7714dd7d42a104a276c2.r2.cloudflarestorage.com',\n",
    "    region_name='us-east-1')\n",
    "\n",
    "bucket_name = 'mv-data-engineer-test'\n",
    "\n",
    "\n",
    "def download_audio_from_s3_bucket_(file_key):\n",
    "    # Setting the patthe Downloads folder\n",
    "    local_filename = os.path.join(\"/Users/anrisroquedacosta/Downloads\", file_key)\n",
    "    \n",
    "    #Creating  necessary dir if theydont exist\n",
    "    os.makedirs(os.path.dirname(local_filename), exist_ok=True)\n",
    "    \n",
    "    # Download the file from the S3 bucket\n",
    "    s3_client.download_file(bucket_name, file_key, local_filename)\n",
    "    \n",
    "    # Print the downloaded file path for debugging\n",
    "    print(f\"File downloaded from the given {file_key} to {local_filename}\")\n",
    "    \n",
    "    return local_filename\n",
    "\n",
    "\n",
    "def list_files_from_s3_dir(dir_prefix):\n",
    "    file_keys = []\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=dir_prefix)\n",
    "\n",
    "    while True:\n",
    "        if \"Contents\" in response:\n",
    "            for obj in response[\"Contents\"]:\n",
    "                file_key = obj[\"Key\"]\n",
    "                \n",
    "                if file_key.endswith('.flac') or file_key.endswith('.mp3'):\n",
    "                    file_keys.append(file_key)\n",
    "\n",
    "        \n",
    "        if response.get(\"IsTruncated\"):\n",
    "            response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=dir_prefix, ContinuationToken=response.get('NextContinuationToken'))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return file_keys\n",
    "\n",
    "\n",
    "def download_all_audio_files():\n",
    "    dir_prefix = \"data/wav48_silence_trimmed/p225/\"  \n",
    "    file_keys = list_files_from_s3_dir(dir_prefix) \n",
    "    \n",
    "    \n",
    "    for file_key in file_keys:\n",
    "        download_audio_from_s3_bucket_(file_key)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_all_audio_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c4c50618-fd66-451c-b2a0-6d9e55c03bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, soundfile as sf, pandas as pd, numpy as np, scipy.signal as sps, noisereduce as nr, whisper, tqdm\n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4f1ccd85-8ee1-4461-9337-30ca0a27ec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterlike_bandpass_filter(y, sr, low=50.0, high=8_000.0, order=6):\n",
    "    sos = sps.butter(order, [low, high], btype=\"band\", fs = sr, output =\"sos\")\n",
    "    return sps.sosfiltfilt(sos, y), sr\n",
    "def stationary_denoisez(y, sr):\n",
    "    return nr.reduce_noise(y=y, sr=sr, stationary= True), sr\n",
    "def resample_to_a_16k(y, sr):\n",
    "    if sr != 16_000:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=16_000)\n",
    "        sr = 16_000\n",
    "    return y.astype(np.float32), sr\n",
    "def clean_wave(y, sr):\n",
    "    for fn in (butterlike_bandpass_filter, stationary_denoisez, resample_to_a_16k):\n",
    "        y, sr = fn(y, sr)\n",
    "    return y, sr\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a5515b48-8cdd-4b0d-9b81-f1ba61f40e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time\n",
    "import numpy as np\n",
    "\n",
    "def tokenise(audio_np_array):\n",
    "    if not isinstance(audio_np_array, np.ndarray):\n",
    "        raise ValueError(\"Input should be a numpy array\")\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        start = time.time()\n",
    "        while True:\n",
    "            n = np.random.randint(20, 1001)\n",
    "            t = torch.randint(-32768, 32767, (n,), dtype=torch.int16, device=\"cuda\")\n",
    "\n",
    "            a = torch.rand(1024, 1024, device=\"cuda\")\n",
    "            _ = torch.matmul(a, a)\n",
    "            if (time.time() -start) *1000 >= 200:\n",
    "                break\n",
    "        return t.cpu()\n",
    "        \n",
    "    n = np.random.randint(20, 1001)\n",
    "    return torch.randint( low = -32768, high=32767, size= (n,), dtype=torch.int16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d1ec9791-ff5a-4e04-be2a-ab30cef30e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = whisper.load_model(\"base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "778f4b45-148e-4bb7-9472-6d1724c786d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(src_path: Path, src_root: Path, dst_root: Path):\n",
    "    rel = src_path.relative_to(src_root)\n",
    "    clean_path = dst_root / rel.with_suffix(\".wav\")\n",
    "    clean_path.parent.mkdir(parents = True, exist_ok=True)\n",
    "\n",
    "\n",
    "    # loading and cleaning data \n",
    "    y, sr = librosa.load(src_path, sr=None, mono=True)\n",
    "    y, sr = clean_wave(y, sr)\n",
    "    sf.write(clean_path, y, sr, subtype=\"PCM_16\")\n",
    "\n",
    "    #tokens_tensor = tokenise(y)\n",
    "    tokens = tokenise(y).tolist()\n",
    "\n",
    "  #sticking for whisper_ base data recog for mel frequency spect\n",
    "    mel = whisper.log_mel_spectrogram(whisper.pad_or_trim(y)).to(whisper_model.device)\n",
    "    txt = whisper_model.decode(mel, whisper.DecodingOptions(language=\"en\")).text\n",
    "\n",
    "    return clean_path, txt.strip(), tokens\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d8a9ddfe-7897-496b-bfa7-1911cfd2bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq, json, librosa\n",
    "from pathlib import Path\n",
    "import pyarrow as pa\n",
    "import statistics, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c09545bf-eb1c-4839-a575-bb81cd6aeea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process(src_root, dst_root, pattern=\"*.flac\"):\n",
    "    src_root, dst_root = Path(src_root), Path(dst_root)\n",
    "    files = list(src_root.rglob(pattern))\n",
    "    rows = []\n",
    "\n",
    "    for p in tqdm.tqdm(files, desc=\"Clean + tokenise + transcribe\"):\n",
    "        clean_path, txt, tokens = process_file(p, src_root, dst_root)\n",
    "        \n",
    "        rows.append({\"id\":  clean_path.relative_to(dst_root).as_posix(),\n",
    "        \"transcription\": txt,\n",
    "        \"tokens\": tokens })\n",
    "    table = pa.Table.from_pylist(rows)\n",
    "    pq.write_table(table, dst_root / \"results.parquet\", compression=\"zstd\")\n",
    "    print(f\"Saved {dst_root / 'results.parquet'} ({len(rows)} rows)\")\n",
    "\n",
    "    summary = { \n",
    "        \"num_files\": len(rows), \n",
    "        \"total_tokens\": sum(len(r[\"tokens\"]) for r in rows), \n",
    "       \"avg_tokens_per_file\":round(statistics.mean(len(r[\"tokens\"]) for r in rows), 2), \n",
    "        \"avg_chars_per_file\": round(statistics.mean(len(r[\"transcription\"]) for r in rows), 2),}\n",
    "    \n",
    "    (dst_root / \"summary.json\").write_text(json.dumps(summary, indent=2))\n",
    "    return rows\n",
    "        \n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "91b88fab-b242-4d4d-ab23-9ca52ee7f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_PREFIX = \"data/wav48_silence_trimmed/p225/\"\n",
    "DL_ROOT   = Path(\"/Users/anrisroquedacosta/Downloads\")\n",
    "DST_ROOT  = Path(\"/Users/anrisroquedacosta/Downloads/new_open\")\n",
    "DST_ROOT.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ec3f661b-70c0-4734-8259-cf19bf2a44b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clean + tokenise + transcribe: 100%|██████████| 303/303 [12:53<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /Users/anrisroquedacosta/Downloads/new_open/results.parquet (303 rows)\n",
      "\n",
      "First 3 rows:\n",
      "                  id                                      transcription  \\\n",
      "0  p225_070_mic2.wav                            That's about to happen.   \n",
      "1  p225_136_mic2.wav  But the Commission is on a collision course wi...   \n",
      "2  p225_016_mic1.wav  Norse, the grave of the bridge, which got past...   \n",
      "\n",
      "                                              tokens  \n",
      "0  [8131, 20375, -12657, -28065, 11304, -14624, 2...  \n",
      "1  [18136, 19590, -21821, 23615, 22511, 21566, -1...  \n",
      "2  [3312, 9824, -14264, 32765, -23431, 12224, -50...  \n",
      "\n",
      "Summary:\n",
      "{'num_files': 303, 'total_tokens': 153469, 'avg_tokens_per_file': 506.5, 'avg_chars_per_file': 44.79}\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # ▸ download every file once\n",
    "    #for key in list_files_from_s3_dir(R2_PREFIX):\n",
    "        #download_audio_from_s3_bucket_(key)\n",
    "\n",
    "    # ▸ process the whole speaker folder once\n",
    "    src_root = DL_ROOT / R2_PREFIX\n",
    "    batch_process(src_root, DST_ROOT)\n",
    "\n",
    "    # ▸ quick peek\n",
    "    print(\"\\nFirst 3 rows:\")\n",
    "    print(pq.read_table(DST_ROOT / \"results.parquet\").to_pandas().head(3))\n",
    "    print(\"\\nSummary:\")\n",
    "    print(json.loads((DST_ROOT / 'summary.json').read_text()))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
